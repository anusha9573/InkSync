# InkSync ğŸ“šChatApp AI Agent ğŸ¤–

InkSync is an intelligent AI assistant that seamlessly analyzes images and supporting documents, delivering context-aware descriptions in the user's preferred language. With its powerful capabilities, InkSync not only interprets visuals but also generates well-structured, downloadable documents.

## ğŸ“ Description

The InkSync and Image Chat Agent is a Streamlit-based web application that allows users to interact with a chatbot trained on text extracted from PDF documents and images. The chatbot is powered by Ollama's LLM and supports multilingual responses.

## ğŸ“¢Demo App with Streamlit Cloud (Visualize only)

[Launch App On Streamlit](https://multi-pdfschatappai-agent.streamlit.app/)

## ğŸ’» Demo:

![Demo 1: Chatbot Output](imagecopy.png)

## ğŸ¯ How It Works:

---

![MultiPDF Chat App Diagram](image.png)

The application follows these steps to provide responses to your questions:

1ï¸âƒ£ Upload Files â€“ Users can upload multiple PDFs and images (JPG, PNG, JPEG).

2ï¸âƒ£ Extract Text & Features â€“

->PDFs: Text is extracted using pdfplumber.

->Images: Text is extracted using OCR (pytesseract), and key features are extracted using ResNet-50.

3ï¸âƒ£ Store Data â€“ The extracted text is split into chunks and stored in a FAISS vector database for efficient retrieval.

4ï¸âƒ£ Ask a Question â€“ Users enter a question related to the uploaded files.

5ï¸âƒ£ Find Relevant Information â€“ The app searches the FAISS database for the most relevant text related to the question.

6ï¸âƒ£ Generate a Response â€“

Uses Ollamaâ€™s Chat Model (qwen2.5) to process the context and generate an answer.

If images were uploaded, the response also includes insights based on extracted features.

7ï¸âƒ£ Multilingual Support â€“ Users can choose a preferred language, and the chatbot provides responses accordingly.

8ï¸âƒ£ Download Report â€“ Users can download a PDF report containing the chatbot's response and extracted content.

---

## ğŸ¯ Key Features

- **Adaptive Chunking** : Uses Sliding Window Chunking to dynamically adjust window size and position, optimizing Retrieval-Augmented Generation (RAG) based on data complexity and context.

- **Multi-Document Conversational QA** : Supports multi-hop queries across multiple documents, overcoming single-document limitations for better contextual understanding.

- **File Compatibility** : Supports PDF and TXT file formats, along with multi-file uploads (PDFs, JPG, PNG, JPEG).

- **Text & Feature Extraction** :

PDFs â†’ Extracts text using pdfplumber.

- **Images** : Extracts text via OCR (pytesseract) and key features using ResNet-50.

- **Fast & Efficient Search** : Uses FAISS vector database for high-speed retrieval of relevant information.

- **AI-Powered Answers** : Leverages Ollamaâ€™s Chat Model (qwen2.5) to generate precise responses.

- **Multilingual Support** : Enables queries and answers in multiple languages.

- **Downloadable Reports** : Provides PDF reports with extracted insights and responses.

![Demo 3: Chatbot Output](img/LLMAgents.jpg)

## ğŸŒŸ Requirements

- **Python 3.8+** â€“ Ensure you have Python installed.
- **FAISS** â€“ For fast similarity search.
- **pdfplumber** â€“ Extracts text from PDF files.
- **pytesseract** â€“ OCR for extracting text from images.
- **ResNet-50** â€“ Extracts key features from images.
- **Ollamaâ€™s Chat Model (qwen2.5)** â€“ AI-powered responses.
- **Flask/FastAPI** â€“ Backend API for processing requests.
- **Torch & Transformers** â€“ Required for AI model inference.
- **Langchain** â€“ Framework for Retrieval-Augmented Generation (RAG).
- **Tika** â€“ Parses various file formats.
- **OpenCV** â€“ Image preprocessing.

## â–¶ï¸Installation

Clone the repository:

`git clone https://github.com/anusha9573/Multi-PDFs_ChatApp_AI-Agent.git`

Install the required Python packages:

`pip install -r requirements.txt`

Run the Streamlit app:

`streamlit run main.py`

---

## ğŸ’¡ Usage

To use the **AI-Powered Document Chat App ğŸ¤–**, you can access it here: [Launch App on Streamlit](https://your-app-link.com/).

If you want to run and implement the project on your system, follow these steps:

1. **Install Dependencies** â€“ Ensure all required dependencies are installed.
2. **Set Up Environment Variables** â€“ Add the **API keys** in the `.env` file (MUST).
3. **Run the Application** â€“ Execute the following command:
   ```bash
   streamlit run main.py
   ```

## Â©ï¸ License ğŸªª

Distributed under the MIT License. See `LICENSE` for more information.

---

#### **If you like this LLM Project do drop â­ to this repo**

#### Follow me on [![LinkedIn](https://img.shields.io/badge/linkedin-%230077B5.svg?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/addepati-anusha-77937a248/) &nbsp; [![GitHub](https://img.shields.io/badge/github-%23121011.svg?style=for-the-badge&logo=github&logoColor=white)](https://github.com/anusha9573)

---

"# InkSync"
